{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "from pyclustering.cluster.silhouette import silhouette_ksearch_type, silhouette_ksearch\n",
    "from pyclustering.cluster.kmeans import kmeans\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from perceptually_important import find_pips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set parameters\n",
    "n_pips = 5\n",
    "lookback = 24\n",
    "hold_period = 6\n",
    "\n",
    "# Global variables\n",
    "unique_pip_indices = []\n",
    "unique_pip_patterns = []\n",
    "pip_clusters = []\n",
    "cluster_centers = []\n",
    "cluster_signals = []\n",
    "selected_long = []\n",
    "selected_short = []\n",
    "fit_martin = None\n",
    "perm_martins = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_cluster_examples(candle_data, cluster_i, grid_size=5):\n",
    "    plt.style.use('dark_background')\n",
    "    fig, axs = plt.subplots(grid_size, grid_size)\n",
    "    flat_axs = axs.flatten()\n",
    "    for i in range(len(flat_axs)):\n",
    "        if i >= len(pip_clusters[cluster_i]):\n",
    "            break\n",
    "\n",
    "        pat_i = unique_pip_indices[pip_clusters[cluster_i][i]]\n",
    "        data_slice = candle_data.iloc[pat_i - lookback + 1: pat_i + 1]\n",
    "        idx = data_slice.index\n",
    "        plot_pip_x, plot_pip_y = find_pips(data_slice['close'].to_numpy(), n_pips, 3)\n",
    "\n",
    "        pip_lines = []\n",
    "        colors = []\n",
    "        for line_i in range(n_pips - 1):\n",
    "            l0 = [(idx[plot_pip_x[line_i]], plot_pip_y[line_i]),\n",
    "                  (idx[plot_pip_x[line_i + 1]], plot_pip_y[line_i + 1])]\n",
    "            pip_lines.append(l0)\n",
    "            colors.append('w')\n",
    "\n",
    "        mpf.plot(data_slice, type='candle', alines=dict(alines=pip_lines, colors=colors),\n",
    "                 ax=flat_axs[i], style='charles', update_width_config=dict(candle_linewidth=1.75))\n",
    "        flat_axs[i].set_yticklabels([])\n",
    "        flat_axs[i].set_xticklabels([])\n",
    "        flat_axs[i].set_xticks([])\n",
    "        flat_axs[i].set_yticks([])\n",
    "        flat_axs[i].set_ylabel(\"\")\n",
    "\n",
    "    fig.suptitle(f\"Cluster {cluster_i}\", fontsize=32)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def predict(pips_y):\n",
    "    norm_y = (np.array(pips_y) - np.mean(pips_y)) / np.std(pips_y)\n",
    "\n",
    "    # Find cluster\n",
    "    best_dist = 1.e30\n",
    "    best_clust = -1\n",
    "    for clust_i in range(len(cluster_centers)):\n",
    "        center = np.array(cluster_centers[clust_i])\n",
    "        dist = np.linalg.norm(norm_y - center)\n",
    "        if dist < best_dist:\n",
    "            best_dist = dist\n",
    "            best_clust = clust_i\n",
    "\n",
    "    if best_clust in selected_long:\n",
    "        return 1.0\n",
    "    elif best_clust in selected_short:\n",
    "        return -1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def train(arr, n_reps=-1):\n",
    "    global data, returns, unique_pip_patterns, unique_pip_indices, pip_clusters, cluster_centers, cluster_signals\n",
    "    global selected_long, selected_short, fit_martin, perm_martins\n",
    "\n",
    "    data = arr\n",
    "    returns = pd.Series(arr).diff().shift(-1)\n",
    "    _find_unique_patterns()\n",
    "\n",
    "    search_instance = silhouette_ksearch(\n",
    "        unique_pip_patterns, 5, 40, algorithm=silhouette_ksearch_type.KMEANS).process()\n",
    "\n",
    "    amount = search_instance.get_amount()\n",
    "    _kmeans_cluster_patterns(amount)\n",
    "\n",
    "    _get_cluster_signals()\n",
    "    _assign_clusters()\n",
    "    fit_martin = _get_total_performance()\n",
    "\n",
    "    print(fit_martin)\n",
    "\n",
    "    if n_reps <= 1:\n",
    "        return\n",
    "\n",
    "    # Start monte carlo permutation test\n",
    "    data_copy = data.copy()\n",
    "    returns_copy = returns.copy()\n",
    "\n",
    "    for rep in range(1, n_reps):\n",
    "        x = np.diff(data_copy).copy()\n",
    "        np.random.shuffle(x)\n",
    "        x = np.concatenate([np.array([data_copy[0]]), x])\n",
    "        data = np.cumsum(x)\n",
    "        returns = pd.Series(data).diff().shift(-1)\n",
    "        print(\"rep\", rep)\n",
    "        _find_unique_patterns()\n",
    "        search_instance = silhouette_ksearch(\n",
    "            unique_pip_patterns, 5, 40, algorithm=silhouette_ksearch_type.KMEANS).process()\n",
    "        amount = search_instance.get_amount()\n",
    "        _kmeans_cluster_patterns(amount)\n",
    "        _get_cluster_signals()\n",
    "        _assign_clusters()\n",
    "        perm_martin = _get_total_performance()\n",
    "        perm_martins.append(perm_martin)\n",
    "\n",
    "\n",
    "def _find_unique_patterns():\n",
    "    global unique_pip_indices, unique_pip_patterns\n",
    "    # Find unique pip patterns in data\n",
    "    unique_pip_indices.clear()\n",
    "    unique_pip_patterns.clear()\n",
    "\n",
    "    last_pips_x = [0] * n_pips\n",
    "    for i in range(lookback - 1, len(data) - hold_period):\n",
    "        start_i = i - lookback + 1\n",
    "        window = data[start_i: i + 1]\n",
    "        pips_x, pips_y = find_pips(window, n_pips, 3)\n",
    "        pips_x = [j + start_i for j in pips_x]\n",
    "\n",
    "        # Check internal pips to see if it is the same as last\n",
    "        same = True\n",
    "        for j in range(1, n_pips - 1):\n",
    "            if pips_x[j] != last_pips_x[j]:\n",
    "                same = False\n",
    "                break\n",
    "\n",
    "        if not same:\n",
    "            # Z-Score normalize pattern\n",
    "            pips_y = list((np.array(pips_y) - np.mean(pips_y)) / np.std(pips_y))\n",
    "            unique_pip_patterns.append(pips_y)\n",
    "            unique_pip_indices.append(i)\n",
    "\n",
    "        last_pips_x = pips_x\n",
    "\n",
    "\n",
    "def _kmeans_cluster_patterns(amount_clusters):\n",
    "    global pip_clusters, cluster_centers\n",
    "    # Cluster Patterns\n",
    "    initial_centers = kmeans_plusplus_initializer(\n",
    "        unique_pip_patterns, amount_clusters).initialize()\n",
    "    kmeans_instance = kmeans(unique_pip_patterns, initial_centers)\n",
    "    kmeans_instance.process()\n",
    "\n",
    "    # Extract clustering results: clusters and their centers\n",
    "    pip_clusters = kmeans_instance.get_clusters()\n",
    "    cluster_centers = kmeans_instance.get_centers()\n",
    "\n",
    "\n",
    "def _get_martin(rets):\n",
    "    rsum = np.sum(rets)\n",
    "    short = False\n",
    "    if rsum < 0.0:\n",
    "        rets *= -1\n",
    "        rsum *= -1\n",
    "        short = True\n",
    "\n",
    "    csum = np.cumsum(rets)\n",
    "    eq = pd.Series(np.exp(csum))\n",
    "    sumsq = np.sum(((eq / eq.cummax()) - 1) ** 2.0)\n",
    "    ulcer_index = (sumsq / len(rets)) ** 0.5\n",
    "    martin = rsum / ulcer_index\n",
    "    if short:\n",
    "        martin = -martin\n",
    "\n",
    "    return martin\n",
    "\n",
    "\n",
    "def _get_cluster_signals():\n",
    "    global cluster_signals\n",
    "    cluster_signals.clear()\n",
    "\n",
    "    for clust in pip_clusters:  # Loop through each cluster\n",
    "        signal = np.zeros(len(data))\n",
    "        for mem in clust:  # Loop through each member in cluster\n",
    "            arr_i = unique_pip_indices[mem]\n",
    "\n",
    "            # Fill signal with 1s following pattern identification\n",
    "            # for hold period specified\n",
    "            signal[arr_i: arr_i + hold_period] = 1.\n",
    "\n",
    "        cluster_signals.append(signal)\n",
    "\n",
    "\n",
    "def _assign_clusters():\n",
    "    global selected_long, selected_short\n",
    "    selected_long.clear()\n",
    "    selected_short.clear()\n",
    "\n",
    "    # Assign clusters to long/short/neutral\n",
    "    cluster_martins = []\n",
    "    for clust_i in range(len(pip_clusters)):  # Loop through each cluster\n",
    "        sig = cluster_signals[clust_i]\n",
    "        sig_ret = returns * sig\n",
    "        martin = _get_martin(sig_ret)\n",
    "        cluster_martins.append(martin)\n",
    "\n",
    "    best_long = np.argmax(cluster_martins)\n",
    "    best_short = np.argmin(cluster_martins)\n",
    "    selected_long.append(best_long)\n",
    "    selected_short.append(best_short)\n",
    "\n",
    "\n",
    "def _get_total_performance():\n",
    "    global selected_long, selected_short, long_signal, short_signal\n",
    "    long_signal = np.zeros(len(data))\n",
    "    short_signal = np.zeros(len(data))\n",
    "\n",
    "    for clust_i in range(len(pip_clusters)):\n",
    "        if clust_i in selected_long:\n",
    "            long_signal += cluster_signals[clust_i]\n",
    "        elif clust_i in selected_short:\n",
    "            short_signal += cluster_signals[clust_i]\n",
    "\n",
    "    long_signal /= len(selected_long)\n",
    "    short_signal /= len(selected_short)\n",
    "    short_signal *= -1\n",
    "\n",
    "    rets = (long_signal + short_signal) * returns\n",
    "\n",
    "    martin = _get_martin(rets)\n",
    "    return martin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.66059582503561\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('BTCUSDT3600.csv')\n",
    "data['date'] = data['date'].astype('datetime64[s]')\n",
    "data = data.set_index('date')\n",
    "data = np.log(data)\n",
    "\n",
    "\n",
    "\n",
    "data = data[data.index < '01-01-2020']\n",
    "arr = data['close'].to_numpy()\n",
    "\n",
    "# Train the model\n",
    "train(arr, n_reps=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
